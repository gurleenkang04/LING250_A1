{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce092a1f-f0cc-491d-a3ca-2458e6920607",
   "metadata": {},
   "source": [
    "# Assignment 1 analysis\n",
    "# Group GKY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "475c0d97-3ca4-43d2-b333-6b7ad801e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.stem import PorterStemmer\n",
    "corpus_root = \"corpus\"\n",
    "texts = PlaintextCorpusReader(corpus_root, '.*')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04473cf-ef5d-45f1-a9ed-6af5ac4f1656",
   "metadata": {},
   "source": [
    "### 1. The length (in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4cb119b-82a6-4040-a0b1-da6e21be36bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subcorpora 1 is 21733 words.\n",
      "Subcorpora 2 is 60275 words.\n",
      "Subcorpora 3 is 8839 words.\n"
     ]
    }
   ],
   "source": [
    "def printLength(text, num):\n",
    "    print(\"Subcorpora \" + str(num) + \" is \" + str(len(text)) + \" words.\")\n",
    "\n",
    "text1 = texts.words('subcorpora1.txt')\n",
    "text2 = texts.words('subcorpora2.txt')\n",
    "text3 = texts.words('subcorpora3.txt')\n",
    "printLength(text1, 1)\n",
    "printLength(text2, 2)\n",
    "printLength(text3, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60932c69-2b0e-441d-9856-89057a20a430",
   "metadata": {},
   "source": [
    "### 2. The lexical diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcb4ce8b-6c4e-4cfb-adef-48659a42aa17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lexical diversity for Subcorpora 1:  0.13201122716606084\n",
      "The lexical diversity for Subcorpora 2:  0.10458730817088345\n",
      "The lexical diversity for Subcorpora 3:  0.23102160877927366\n"
     ]
    }
   ],
   "source": [
    "# opening files\n",
    "data1 = texts.words('subcorpora1.txt')\n",
    "data2 = texts.words('subcorpora2.txt')\n",
    "data3 = texts.words('subcorpora3.txt')\n",
    "\n",
    "def lexical_diversity(data):\n",
    "    return len(set(data)) / len(data)\n",
    "\n",
    "# printing lexical diversity\n",
    "print(\"The lexical diversity for Subcorpora 1: \", lexical_diversity(data1))\n",
    "print(\"The lexical diversity for Subcorpora 2: \", lexical_diversity(data2))\n",
    "print(\"The lexical diversity for Subcorpora 3: \", lexical_diversity(data3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec275b13-5cda-423f-9258-159a0ef7cd25",
   "metadata": {},
   "source": [
    "### 3. Top 10 most frequent words and their counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d78318f7-d251-4545-993b-7c20d7c4b175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subcorpora1: \n",
      "[('the', 518), ('BARRY', 358), ('and', 290), ('Barry', 259), ('you', 210), ('VANESSA', 162), ('You', 118), ('that', 116), ('ADAM', 111), ('out', 98)]\n",
      "Subcorpora2: \n",
      "[('the', 2224), ('and', 1516), ('was', 766), ('that', 588), ('his', 453), ('you', 413), ('with', 411), ('had', 380), ('her', 369), ('for', 294)]\n",
      "Subcorpora3: \n",
      "[('the', 401), ('and', 171), ('prediction', 101), ('for', 82), ('intelligence', 77), ('that', 77), ('tasks', 76), ('artificial', 72), ('decision', 56), ('labor', 56)]\n"
     ]
    }
   ],
   "source": [
    "text1 = texts.words('subcorpora1.txt')\n",
    "text2 = texts.words('subcorpora2.txt')\n",
    "text3 = texts.words('subcorpora3.txt')\n",
    "\n",
    "print (\"Subcorpora1: \")\n",
    "\n",
    "filtered = [word for word in text1 if word.isalpha() and len(word) > 2]\n",
    "fdist1 = FreqDist(filtered) \n",
    "print(fdist1.most_common(10))\n",
    "\n",
    "print (\"Subcorpora2: \")\n",
    "\n",
    "filtered = [word for word in text2 if word.isalpha() and len(word) > 2]\n",
    "fdist2 = FreqDist(filtered)\n",
    "print(fdist2.most_common(10))\n",
    "\n",
    "print (\"Subcorpora3: \")\n",
    "\n",
    "filtered = [word for word in text3 if word.isalpha () and len(word) > 2] \n",
    "fdist3 = FreqDist(filtered)\n",
    "print(fdist3.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1195fa0b-90c1-4187-85ca-657171b4ad2b",
   "metadata": {},
   "source": [
    "### 4. Words that are at least 10 characters long and their counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbebe095-5671-4c6a-b66b-cfb127022017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subcorpora1: \n",
      "[('pollination', 5), ('Affirmative', 3), ('conditioner', 3), ('automatically', 2), ('Congratulations', 2), ('grandmother', 2), ('representing', 2), ('Overreacting', 2), ('dramatically', 2), ('uncounscious', 2)]\n",
      "Subcorpora2: \n",
      "[('immediately', 16), ('conversation', 10), ('impatiently', 7), ('interrupted', 7), ('disappeared', 7), ('Klipspringer', 7), ('incessantly', 6), ('interesting', 5), ('incredulously', 5), ('continually', 5)]\n",
      "Subcorpora3: \n",
      "[('intelligence', 77), ('predictions', 15), ('radiologists', 15), ('uncertainty', 14), ('complementary', 9), ('productivity', 8), ('applications', 7), ('information', 6), ('technologies', 5), ('transcription', 5)]\n"
     ]
    }
   ],
   "source": [
    "text1 = texts.words('subcorpora1.txt')\n",
    "text2 = texts.words('subcorpora2.txt')\n",
    "text3 = texts.words('subcorpora3.txt')\n",
    "\n",
    "print (\"Subcorpora1: \")\n",
    "\n",
    "sorted(set(w.lower() for w in text1))\n",
    "\n",
    "filtered1 = [word for word in text1 if word.isalpha() and len(word) > 10]\n",
    "fdist1 = FreqDist(filtered1)\n",
    "print(fdist1.most_common(10))\n",
    "\n",
    "print (\"Subcorpora2: \")\n",
    "\n",
    "sorted(set(w.lower() for w in text2))\n",
    "\n",
    "filtered2 = [word for word in text2 if word.isalpha() and len(word) > 10] \n",
    "fdist2 = FreqDist(filtered2)\n",
    "print(fdist2.most_common(10))\n",
    "\n",
    "print (\"Subcorpora3: \")\n",
    "\n",
    "sorted(set(w.lower() for w in text3))\n",
    "\n",
    "filtered3 = [word for word in text3 if word.isalpha() and len(word) > 10] \n",
    "fdist3 = FreqDist(filtered3)\n",
    "print(fdist3.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b74a52-61cd-4958-9d4c-4e9fc88ac198",
   "metadata": {},
   "source": [
    "### 5. The longest sentence (type the sentence and give the number of words). Hint: look\n",
    "### at the Gutenberg part of Section 2.1 in NLTK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fda65d97-9cd6-44ee-b280-77982e272b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Men in suits are pushing all the honey of the aisle and into carts) We demand an end to the glorification of the bear as anything more (We see a statue of a bear-shaped honey container being pulled down by bees) than a filthy, smelly, bad-breath stink machine.\n",
      "\n",
      "\n",
      "In addition to all these I can remember that Faustina O’ Brien came there at least once and the Baedeker girls and young Brewer, who had his nose shot off in the war, and Mr. Albrucksburger and Miss Haag, his fiancée, and Ardita Fitz-Peters and Mr. P. Jewett, once head of the American Legion, and Miss Claudia Hip, with a man reputed to be her chauffeur, and a prince of something, whom we called Duke, and whose name, if I ever knew it, I have forgotten.\n",
      "\n",
      "\n",
      "Cockburn, Henderson, and Stern (2019) describe this insight: ÒThe challenge presented by advances in artificial intelligence is that they appear to be research tools that not only have the potential to change the method of innovation itself, but also have implications across a wide range of fields. Ó Agrawal, McHale, and Oettl explain how artificial intelligence may influence the knowledge production function (2019a) and model the implications of using artificial intelligence to produce a map of the complex combinatorial search space of ideas for the purpose of reducing the cost of predicting which combinations of ideas offer the greatest promise (2019b).\n"
     ]
    }
   ],
   "source": [
    "subcorpora1_sentences = texts.sents('subcorpora1.txt')\n",
    "subcorpora2_sentences = texts.sents('subcorpora2.txt')\n",
    "subcorpora3_sentences = texts.sents('subcorpora3.txt')\n",
    "\n",
    "def find_longest(sentences):\n",
    "    longest_length = max(len(s) for s in sentences) \n",
    "    longest_sentence = [s for s in sentences if len(s) == longest_length]\n",
    "    return longest_sentence\n",
    "\n",
    "def format_sentence(longest_sentence):\n",
    "     # format each sentence properly\n",
    "    for sentence in longest_sentence:\n",
    "        formatted_sentence = ''\n",
    "        \n",
    "        for i, word in enumerate(sentence):\n",
    "            if i == 0:\n",
    "                # dont add a space before the first word in a sentence\n",
    "                formatted_sentence += word\n",
    "                \n",
    "            elif i > 0 and sentence[i-1] == '(':\n",
    "                # no space after '('\n",
    "                formatted_sentence += word\n",
    "                \n",
    "            elif word == ')':\n",
    "                # no space before ')'\n",
    "                formatted_sentence += word\n",
    "                \n",
    "            elif word == '-':\n",
    "                # no space before '-'\n",
    "                formatted_sentence += word\n",
    "                \n",
    "            elif i > 0 and sentence[i-1] == '-':\n",
    "                # no space after '-'\n",
    "                formatted_sentence += word\n",
    "                \n",
    "            elif word == \"’\":\n",
    "                # no space before '’'\n",
    "                formatted_sentence += word\n",
    "                \n",
    "            elif word in [',', '.', '!', '?', ':', ';', ')', ').']:\n",
    "                # check if word is punctuation (no space before punctuation)\n",
    "                formatted_sentence += word\n",
    "                \n",
    "            else:\n",
    "                # add a space before regular words\n",
    "                formatted_sentence += ' ' + word\n",
    "        \n",
    "        return formatted_sentence\n",
    "\n",
    "sentence1 = find_longest(subcorpora1_sentences)\n",
    "sentence2 = find_longest(subcorpora2_sentences)\n",
    "sentence3 = find_longest(subcorpora3_sentences)\n",
    "\n",
    "formatted1 = format_sentence(sentence1)\n",
    "formatted2 = format_sentence(sentence2)\n",
    "formatted3 = format_sentence(sentence3)\n",
    "\n",
    "print(formatted1)\n",
    "print('\\n')     # this adds a paragraph line break between the sentences\n",
    "print(formatted2)\n",
    "print('\\n')\n",
    "print(formatted3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cb9e17-28e3-4abc-90b9-9094d85830f1",
   "metadata": {},
   "source": [
    "### 6. A stemmed version of the longest sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70b690db-a3af-489b-bc24-f3d1fa41e4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( men in suit are push all the honey of the aisl and into cart ) we demand an end to the glorif of the bear as anyth more ( we see a statu of a bear - shape honey contain be pull down by bee ) than a filthi , smelli , bad - breath stink machin . \n",
      "\n",
      "in addit to all these i can rememb that faustina o ’ brien came there at least onc and the baedek girl and young brewer , who had hi nose shot off in the war , and mr . albrucksburg and miss haag , hi fiancé , and ardita fitz - peter and mr . p . jewett , onc head of the american legion , and miss claudia hip , with a man reput to be her chauffeur , and a princ of someth , whom we call duke , and whose name , if i ever knew it , i have forgotten . \n",
      "\n",
      "cockburn , henderson , and stern ( 2019 ) describ thi insight : òthe challeng present by advanc in artifici intellig is that they appear to be research tool that not onli have the potenti to chang the method of innov itself , but also have implic across a wide rang of field . ó agraw , mchale , and oettl explain how artifici intellig may influenc the knowledg product function ( 2019a ) and model the implic of use artifici intellig to produc a map of the complex combinatori search space of idea for the purpos of reduc the cost of predict which combin of idea offer the greatest promis ( 2019b ). "
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "for word in sentence1[0]:\n",
    "    print(ps.stem(word), end=\" \")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "for word in sentence2[0]:\n",
    "    print(ps.stem(word), end=\" \")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "for word in sentence3[0]:\n",
    "    print(ps.stem(word), end=\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
